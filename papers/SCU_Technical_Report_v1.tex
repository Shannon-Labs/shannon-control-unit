\documentclass[11pt]{article}
\usepackage[utf8]{inputenc} 
\usepackage[T1]{fontenc}    
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}       
\usepackage{url}            
\usepackage{booktabs}       
\usepackage{amsfonts}       
\usepackage{nicefrac}       
\usepackage{microtype}      
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{authblk}

\title{\textbf{Shannon Control Unit: Closed-Loop Control System for Real-Time Neural Network Training Regulation}}

\author{Hunter Bown}
\affil{Shannon Labs, Dallas, TX \\ \texttt{hunter@shannonlabs.dev}}
\date{}

\begin{document}
\maketitle

\begin{abstract}
\noindent We present the Shannon Control Unit (SCU), a closed-loop regularization mechanism for language model training. SCU treats the MDL information ratio as a controlled variable and adjusts the regularization coefficient ($\lambda$) via a proportional-integral (PI) controller. By aligning $\lambda$ with the observed imbalance between parameter complexity and data fit, SCU maintains a target information ratio ($S^*$) throughout optimization. Experiments on Llama 3.2 1B and 3B fine-tuning show consistent reductions in bits-per-token relative to tuned fixed-$\lambda$ baselines, without manual retuning of control gains.
\end{abstract}

\section{Introduction}
Large language model training exhibits time-varying overfitting pressure: early phases reward rapid complexity growth, while later phases benefit from stronger regularization. Standard penalties (weight decay, dropout) are scheduled open-loop and cannot adapt to these shifts without costly hyperparameter sweeps. Adaptive optimizers (Adam, RMSProp) adjust step sizes from gradient statistics but do not regulate model complexity against an information budget. We propose a feedback controller that measures the balance between parameter complexity and data fit and adjusts $\lambda$ to maintain a target information ratio.

\section{Related Work}
\textbf{Control Theory in Neural Networks:} Shao et al. (2020) applied PI control to VAEs, but focused on KL divergence, distinct from our parameter/data bit allocation ratios.

\noindent \textbf{Adaptive Regularization:} Glandorf et al. (2023) utilized iterative schedules but lacked closed-loop feedback.

\noindent \textbf{Information-Theoretic Approaches:} Tishby \& Shwartz-Ziv (2017) provided static analysis of the Information Bottleneck but offered no dynamic control mechanism.

\section{Methodology}

\subsection{Control Algorithm}
Let DataBPT denote the bits-per-token training loss and ParamBPT the bits-per-token parameter update cost (e.g., KL term for a prior). Define the information ratio
\[
S(t) = \frac{\text{ParamBPT}(t)}{\text{DataBPT}(t) + \text{ParamBPT}(t)}.
\]
The control objective is $S(t) \to S^*$. With error $e(t) = S(t) - S^*$, SCU updates
\[
I(t) = I(t-1) + e(t),
\]
\[
u(t) = K_p \cdot e(t) + K_i \cdot I(t),
\]
\[
\lambda(t+1) = \lambda(t) \cdot \exp\big(-u(t)\big),
\]
where the negative sign reflects that increasing $\lambda$ decreases $S$ ($\partial S / \partial \lambda < 0$). Deadband, leakage, or clamping on $I(t)$ mitigate windup; updates occur at gradient-accumulation boundaries. Default gains: $K_p=0.8$, $K_i=0.15$; deadband $\pm 0.2$ percentage points.

\section{Experimental Validation}
On Llama 3.2 1B/3B fine-tuning (WikiText-103 subset), SCU tracks $S^*$ within $\pm 0.2$pp and reduces BPT by 6-12\% versus tuned fixed-$\lambda$ sweeps, using a single set of control gains across scales. Control logs and metrics are provided in the repository.

\begin{table}[h]
  \centering
  \begin{tabular}{lllll}
    \toprule
    Model & Target $S$ & Achieved $S$ & Error & Converged $\lambda$ \\
    \midrule
    1B & 3.25\% & 3.24\% & 0.01\% & 1.000 \\
    3B & 3.00\% & 3.01\% & 0.01\% & 2.607 \\
    \bottomrule
  \end{tabular}
  \caption{Representative steady-state $S$ and $\lambda$ values from a run.}
\end{table}

\section{Conclusion}
The Shannon Control Unit provides a robust mechanism for adaptive regularization via control theory. By treating the training process as a dynamic system to be controlled rather than a static optimization problem, we achieve higher stability and automatic hyperparameter tuning.

\section*{Note on Intellectual Property}
This methodology is detailed in U.S. Provisional Patent Application 63/868,930, filed September 2, 2025.

\end{document}
